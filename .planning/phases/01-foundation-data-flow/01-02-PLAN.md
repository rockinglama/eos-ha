---
phase: 01-foundation-data-flow
plan: 02
type: execute
wave: 2
depends_on: ["01-01"]
files_modified:
  - custom_components/eos_ha/__init__.py
  - custom_components/eos_ha/api.py
  - custom_components/eos_ha/coordinator.py
  - custom_components/eos_ha/sensor.py
autonomous: true

must_haves:
  truths:
    - "Integration runs periodic optimization cycle every 5 minutes via DataUpdateCoordinator"
    - "Integration reads price, SOC, and consumption from user-selected HA entities"
    - "Integration fetches 48h PV forecast from Akkudoktor API with 6-hour caching"
    - "Integration builds EOS-format request and sends it to EOS server"
    - "Integration parses EOS response and extracts ac_charge, dc_charge, discharge_allowed arrays"
    - "Integration skips optimization when input entities are unavailable and keeps last valid results"
    - "Integration handles EOS server errors gracefully without log spam"
    - "Optimization status sensor shows whether last run succeeded with timestamp"
  artifacts:
    - path: "custom_components/eos_ha/api.py"
      provides: "Async EOS and Akkudoktor API clients"
      contains: "class EOSApiClient"
    - path: "custom_components/eos_ha/coordinator.py"
      provides: "DataUpdateCoordinator subclass running optimization cycle"
      contains: "class EOSCoordinator"
    - path: "custom_components/eos_ha/__init__.py"
      provides: "Integration setup wiring coordinator to config entry"
      contains: "async_setup_entry"
    - path: "custom_components/eos_ha/sensor.py"
      provides: "Optimization status sensor entity"
      contains: "class EOSOptimizationStatusSensor"
  key_links:
    - from: "custom_components/eos_ha/coordinator.py"
      to: "custom_components/eos_ha/api.py"
      via: "calls EOSApiClient.optimize and AkkudoktorApiClient.get_pv_forecast"
      pattern: "self\\._eos_client|self\\._akkudoktor_client"
    - from: "custom_components/eos_ha/coordinator.py"
      to: "HA entity states"
      via: "self.hass.states.get() for price, SOC, consumption entities"
      pattern: "hass\\.states\\.get"
    - from: "custom_components/eos_ha/__init__.py"
      to: "custom_components/eos_ha/coordinator.py"
      via: "creates EOSCoordinator and calls async_config_entry_first_refresh"
      pattern: "EOSCoordinator|async_config_entry_first_refresh"
    - from: "custom_components/eos_ha/sensor.py"
      to: "custom_components/eos_ha/coordinator.py"
      via: "CoordinatorEntity reads coordinator.data for status"
      pattern: "CoordinatorEntity|coordinator\\.data"
---

<objective>
Implement the complete optimization data flow: API clients for EOS server and Akkudoktor, DataUpdateCoordinator for periodic optimization, integration setup wiring, and optimization status sensor entity.

Purpose: This is the core engine of the integration — collecting data from HA entities and Akkudoktor API, building the EOS request, sending it, parsing the response, and exposing optimization health via a status sensor. Without this, the integration has UI but no functionality.
Output: Working end-to-end optimization cycle that runs every 5 minutes and reports status via a sensor entity.
</objective>

<execution_context>
@/Users/idueck/.claude/get-shit-done/workflows/execute-plan.md
@/Users/idueck/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-foundation-data-flow/01-RESEARCH.md
@.planning/phases/01-foundation-data-flow/01-CONTEXT.md
@.planning/phases/01-foundation-data-flow/01-01-SUMMARY.md
@src/interfaces/optimization_backends/optimization_backend_eos.py
@src/interfaces/pv_interface.py
@src/interfaces/optimization_interface.py
@src/eos_ha.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create async API clients for EOS server and Akkudoktor</name>
  <files>
    custom_components/eos_ha/api.py
  </files>
  <action>
Create `api.py` with two async client classes that encapsulate all external API communication.

**class EOSApiClient:**
- `__init__(self, session: aiohttp.ClientSession, base_url: str)` — store session and URL
- `async def validate_server(self) -> dict` — GET `{base_url}/v1/health`, return parsed JSON. Raise `EOSConnectionError` on failure. This method is also usable by Config Flow for validation.
- `async def optimize(self, eos_request: dict, start_hour: int) -> dict` — POST to `{base_url}/optimize?start_hour={start_hour}` with JSON body, timeout 180 seconds. Return parsed JSON response. The `start_hour` parameter matches existing pattern in `optimization_backend_eos.py` line 100-108. Set headers `{"accept": "application/json", "Content-Type": "application/json"}`.
  - On success (200): return `response.json()`
  - On non-200: raise `EOSOptimizationError(f"EOS returned status {resp.status}")`
  - On timeout: raise `EOSOptimizationError("EOS optimization timed out")`
  - On connection error: raise `EOSConnectionError(str(err))`

**class AkkudoktorApiClient:**
- `__init__(self, session: aiohttp.ClientSession)` — store session
- `async def get_pv_forecast(self, lat: float, lon: float, azimuth: float = 180, tilt: float = 30, power: float = 1000, power_inverter: float = 1000, inverter_efficiency: float = 1.0, timezone: str = "UTC") -> list[float]` — Build URL from `AKKUDOKTOR_API_URL` (from const.py) with query params matching `pv_interface.py` line 381-409: `lat`, `lon`, `azimuth`, `tilt`, `power`, `powerInverter`, `inverterEfficiency`, `timezone`. Timeout 10 seconds.
  - Parse response: `data = await resp.json()`, extract `data["values"]` which is a list of lists of dicts with `datetime` and `power` keys
  - Process into 48-hour hourly array following the pattern in `pv_interface.py` lines 691-776:
    - Filter entries from midnight today to 48 hours ahead (use timezone-aware datetimes)
    - Extract `power` values, clamp negatives to 0
    - Apply the workaround: remove first entry and append 0 (line 719-721)
    - Pad or trim to exactly 48 values
  - On any error: raise `AkkudoktorApiError`

**Custom exceptions** (define at top of api.py):
- `class EOSConnectionError(Exception): pass`
- `class EOSOptimizationError(Exception): pass`
- `class AkkudoktorApiError(Exception): pass`

Use `aiohttp.ClientTimeout` for all timeout values. Import `AKKUDOKTOR_API_URL` from const. Use `homeassistant.util.dt as dt_util` for timezone-aware datetime operations (per STATE.md blocker: use dt_util.now() not datetime.now()).
  </action>
  <verify>
Run: `python -c "import ast; tree=ast.parse(open('custom_components/eos_ha/api.py').read()); classes=[n.name for n in ast.walk(tree) if isinstance(n, ast.ClassDef)]; assert 'EOSApiClient' in classes; assert 'AkkudoktorApiClient' in classes; print('api.py OK')"`
  </verify>
  <done>
api.py defines EOSApiClient (validate_server, optimize) and AkkudoktorApiClient (get_pv_forecast) with proper async patterns, custom exceptions, and timeout handling. PV forecast processing matches existing Akkudoktor patterns from the codebase.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create DataUpdateCoordinator with optimization cycle and request building</name>
  <files>
    custom_components/eos_ha/coordinator.py
  </files>
  <action>
Create `coordinator.py` with the `EOSCoordinator(DataUpdateCoordinator)` class that orchestrates the complete optimization cycle.

**class EOSCoordinator(DataUpdateCoordinator):**

`__init__(self, hass, config_entry)`:
- Call super().__init__ with name="EOS Optimization", update_interval=timedelta(seconds=DEFAULT_SCAN_INTERVAL)
- Store config_entry
- Create a shared `aiohttp.ClientSession` using `aiohttp.ClientSession()` — this session is reused across all API calls (per research anti-pattern: don't create session per request)
- Create `EOSApiClient(self.session, config_entry.data[CONF_EOS_URL])`
- Create `AkkudoktorApiClient(self.session)`
- Initialize PV forecast cache: `self._pv_forecast_cache: list[float] | None = None` and `self._pv_forecast_timestamp: datetime | None = None`

`async def _async_update_data(self) -> dict`:
This is the core optimization cycle. Steps:

1. **Read HA input entities** (INPUT-01, INPUT-02, INPUT-03):
   - Get price, SOC, consumption entities from config_entry.data using their CONF_* keys
   - Use `self.hass.states.get(entity_id)` for each
   - Check for unavailability: if any entity is None, or state is `STATE_UNAVAILABLE` or `STATE_UNKNOWN` → log at debug level which entity is unavailable, return last valid data (`self.data`) if available, otherwise raise `UpdateFailed("Required input entities unavailable")`
   - Per user decision: skip optimization, keep last valid results, try again next cycle

2. **Fetch PV forecast with caching** (INPUT-04):
   - Call `self._get_pv_forecast_cached()` (private method)
   - If returns None (cache expired + API down): raise `UpdateFailed("PV forecast unavailable and cache expired")`

3. **Build EOS request** (INPUT-05):
   - Call `self._build_eos_request(price_state, soc_state, consumption_state, pv_forecast)` (private method)

4. **Send optimization** (OPT-01):
   - Get current hour: `dt_util.now().hour`
   - Call `self._eos_client.optimize(eos_request, current_hour)`
   - On `EOSConnectionError` or `EOSOptimizationError`: raise `UpdateFailed(str(err))`

5. **Parse response** (OPT-02):
   - Call `self._parse_optimization_response(result)` (private method)
   - Return structured dict with all parsed data

**Private method `_get_pv_forecast_cached(self) -> list[float] | None`:**
- Check cache validity: cache exists AND timestamp is less than PV_FORECAST_CACHE_HOURS old (use dt_util.now() for comparison)
- If cache valid: return cache, log at debug "Using cached PV forecast"
- If cache invalid or missing: try fetching from Akkudoktor API
  - Get lat/lon from config_entry.data
  - Call `self._akkudoktor_client.get_pv_forecast(lat, lon, timezone=self.hass.config.time_zone)`
  - On success: update cache and timestamp, return forecast
  - On `AkkudoktorApiError`: log warning, return cached data if available (even if expired), return None if no cache at all
  - Per user decision: "cache last successful forecast, use cached data if API is down (cache valid for 6 hours)"

**Private method `_build_eos_request(self, price_state, soc_state, consumption_state, pv_forecast) -> dict`:**
Build request matching the existing EOS format from `eos_ha.py` lines 607-619:

```python
{
    "ems": {
        "pv_prognose_wh": pv_forecast,  # list[float], 48 values
        "strompreis_euro_pro_wh": self._extract_price_forecast(price_state),
        "einspeiseverguetung_euro_pro_wh": [0.0] * 48,  # Feed-in tariff, 0 for v1
        "preis_euro_pro_wh_akku": 0.0,  # Battery cost per Wh, 0 for v1
        "gesamtlast": self._extract_consumption_forecast(consumption_state),
    },
    "pv_akku": {
        "capacity_wh": self.config_entry.data[CONF_BATTERY_CAPACITY] * 1000,  # kWh → Wh
        "charging_efficiency": 0.95,  # Default efficiency
        "discharging_efficiency": 0.95,
        "max_charge_power_w": self.config_entry.data[CONF_MAX_CHARGE_POWER],
        "initial_soc_percentage": round(float(soc_state.state)),
        "min_soc_percentage": self.config_entry.data[CONF_MIN_SOC],
        "max_soc_percentage": self.config_entry.data[CONF_MAX_SOC],
    },
    "inverter": {
        "max_power_wh": self.config_entry.data[CONF_INVERTER_POWER],
    },
    "temperature_forecast": [15.0] * 48,  # Default temperature, same as pv_interface.py line 585
}
```

Note: `capacity_wh` conversion from kWh to Wh is critical — user enters kWh but EOS expects Wh.

**Private method `_extract_price_forecast(self, price_state) -> list[float]`:**
- For v1, use the current price value replicated across 48 hours: `[float(price_state.state)] * 48`
- This is a simplification — Tibber provides future prices via attributes but parsing varies. Replicating current price is the safe v1 approach.
- If price_state.state cannot be converted to float, use 0.0

**Private method `_extract_consumption_forecast(self, consumption_state) -> list[float]`:**
- Use current consumption value replicated across 48 hours: `[float(consumption_state.state)] * 48`
- Same v1 simplification as price
- If cannot convert to float, use 500.0 (reasonable default ~500Wh per hour)

**Private method `_parse_optimization_response(self, response: dict) -> dict`:**
- Extract from response (matching optimization_interface.py lines 164-200):
  - `ac_charge`: list of floats (relative charge demand per hour, 0.0-1.0)
  - `dc_charge`: list of floats
  - `discharge_allowed`: list of bools/ints (1=allowed, 0=not)
  - `start_solution`: list (for next optimization warm start)
- If "error" key in response or expected keys missing: log error and raise `UpdateFailed`
- Return structured dict:
  ```python
  {
      "ac_charge": response.get("ac_charge", []),
      "dc_charge": response.get("dc_charge", []),
      "discharge_allowed": response.get("discharge_allowed", []),
      "start_solution": response.get("start_solution"),
      "raw_response": response,
      "last_update": dt_util.now().isoformat(),
      "last_success": True,
  }
  ```

**Cleanup method `async def async_shutdown(self)`:**
- Close the aiohttp session: `await self.session.close()`
  </action>
  <verify>
Run: `python -c "import ast; tree=ast.parse(open('custom_components/eos_ha/coordinator.py').read()); classes=[n.name for n in ast.walk(tree) if isinstance(n, ast.ClassDef)]; assert 'EOSCoordinator' in classes; methods=[n.name for n in ast.walk(tree) if isinstance(n, ast.AsyncFunctionDef)]; assert '_async_update_data' in methods; print('coordinator.py OK')"`
  </verify>
  <done>
coordinator.py implements EOSCoordinator with: _async_update_data running the full optimization cycle, PV forecast caching with 6-hour expiry, EOS request building (kWh→Wh conversion), response parsing extracting ac_charge/dc_charge/discharge_allowed, graceful error handling with UpdateFailed, and session management.
  </done>
</task>

<task type="auto">
  <name>Task 3: Wire integration setup and create optimization status sensor</name>
  <files>
    custom_components/eos_ha/__init__.py
    custom_components/eos_ha/sensor.py
  </files>
  <action>
**Update __init__.py** — Replace the stub from Plan 01 with full integration setup:

```python
async def async_setup_entry(hass: HomeAssistant, entry: ConfigEntry) -> bool:
    """Set up EOS HA from a config entry."""
    coordinator = EOSCoordinator(hass, entry)

    # Perform initial data fetch — raises ConfigEntryNotReady on failure
    # This MUST be called before platform setup (per STATE.md blocker)
    await coordinator.async_config_entry_first_refresh()

    # Store coordinator for platform access
    hass.data.setdefault(DOMAIN, {})
    hass.data[DOMAIN][entry.entry_id] = coordinator

    # Forward setup to sensor platform
    await hass.config_entries.async_forward_entry_setups(entry, PLATFORMS)

    return True

async def async_unload_entry(hass: HomeAssistant, entry: ConfigEntry) -> bool:
    """Unload a config entry."""
    unload_ok = await hass.config_entries.async_unload_platforms(entry, PLATFORMS)
    if unload_ok:
        coordinator: EOSCoordinator = hass.data[DOMAIN].pop(entry.entry_id)
        await coordinator.async_shutdown()
    return unload_ok
```

Import: `ConfigEntry`, `HomeAssistant`, `DOMAIN` from const, `PLATFORMS = ["sensor"]`, `EOSCoordinator` from coordinator.

**Create sensor.py** — Optimization status sensor (per user decision: "expose whether last run was successful + timestamp"):

```python
class EOSOptimizationStatusSensor(CoordinatorEntity, SensorEntity):
```

`async_setup_entry(hass, config_entry, async_add_entities)`:
- Get coordinator from `hass.data[DOMAIN][config_entry.entry_id]`
- Create and add `EOSOptimizationStatusSensor(coordinator)`

**EOSOptimizationStatusSensor(CoordinatorEntity, SensorEntity):**
- `__init__(self, coordinator)`:
  - Call `super().__init__(coordinator)`
  - `self._attr_unique_id = f"{coordinator.config_entry.entry_id}_optimization_status"`
  - `self._attr_name = "EOS Optimization Status"`
  - `self._attr_icon = "mdi:chart-timeline-variant"`

- `native_value` property:
  - If `self.coordinator.data` and `self.coordinator.data.get("last_success")`: return `"optimized"`
  - If `self.coordinator.last_update_success is False`: return `"failed"`
  - Return `"unknown"`

- `extra_state_attributes` property:
  - Return dict with:
    - `"last_update"`: `self.coordinator.data.get("last_update")` if data exists, else None
    - `"last_success"`: `self.coordinator.data.get("last_success")` if data exists, else None
    - `"eos_server_url"`: `self.coordinator.config_entry.data.get(CONF_EOS_URL)`
    - `"update_interval_seconds"`: `DEFAULT_SCAN_INTERVAL`

Import: `CoordinatorEntity` from `homeassistant.helpers.update_coordinator`, `SensorEntity` from `homeassistant.components.sensor`, `DOMAIN`, config key constants from const.
  </action>
  <verify>
Run: `python -c "import ast; tree=ast.parse(open('custom_components/eos_ha/__init__.py').read()); funcs=[n.name for n in ast.walk(tree) if isinstance(n, ast.AsyncFunctionDef)]; assert 'async_setup_entry' in funcs; assert 'async_unload_entry' in funcs; print('__init__.py OK')"` and
`python -c "import ast; tree=ast.parse(open('custom_components/eos_ha/sensor.py').read()); classes=[n.name for n in ast.walk(tree) if isinstance(n, ast.ClassDef)]; assert 'EOSOptimizationStatusSensor' in classes; print('sensor.py OK')"`
  </verify>
  <done>
__init__.py creates EOSCoordinator, calls async_config_entry_first_refresh before platform setup, stores coordinator in hass.data, forwards to sensor platform, cleans up on unload. sensor.py provides EOSOptimizationStatusSensor showing "optimized"/"failed"/"unknown" with last_update timestamp and server URL in attributes.
  </done>
</task>

</tasks>

<verification>
1. `api.py` defines EOSApiClient and AkkudoktorApiClient with async methods and custom exceptions
2. `coordinator.py` defines EOSCoordinator(DataUpdateCoordinator) with _async_update_data implementing full optimization cycle
3. `coordinator.py` reads from HA entities, fetches PV forecast with caching, builds EOS request, sends and parses response
4. `coordinator.py` converts battery capacity from kWh (config) to Wh (EOS request)
5. `coordinator.py` handles missing entities by returning last valid data
6. `coordinator.py` handles PV forecast API failures with 6-hour cache
7. `__init__.py` creates coordinator, calls async_config_entry_first_refresh, forwards to sensor platform
8. `__init__.py` cleans up coordinator session on unload
9. `sensor.py` defines EOSOptimizationStatusSensor showing optimization health and timestamp
10. All Python files pass `ast.parse()` (valid syntax)
11. No blocking I/O (no requests library, no time.sleep) — all async with aiohttp
12. Uses dt_util.now() instead of datetime.now() for timezone-aware operations
</verification>

<success_criteria>
- EOSApiClient correctly calls /optimize with start_hour parameter and /v1/health for validation
- AkkudoktorApiClient builds correct Akkudoktor API URL and processes response into 48-value array
- EOSCoordinator._async_update_data implements complete cycle: read entities → get PV → build request → optimize → parse response
- PV forecast cache works: returns cached data within 6 hours, fetches fresh after expiry, falls back to expired cache on API error
- Missing HA entities: optimization skipped, last data preserved, debug-level logging only
- EOS request format matches existing codebase (ems, pv_akku, inverter, temperature_forecast keys)
- Battery capacity correctly converted kWh → Wh in request building
- Optimization status sensor shows "optimized", "failed", or "unknown" with attributes
- No synchronous/blocking code — all I/O uses async/await
- Integration setup calls async_config_entry_first_refresh before platform setup
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation-data-flow/01-02-SUMMARY.md`
</output>
